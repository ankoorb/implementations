{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62bd3d21-6be1-441c-8ea3-ab478069f630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3e0fab-b38c-42fe-87e8-6eec7aad8d06",
   "metadata": {},
   "source": [
    "# [Batch Normalization](https://arxiv.org/pdf/1502.03167)\n",
    "\n",
    "Given a mini-batch of activations $ x = \\{x_1, x_2, \\dots, x_m\\} $, the batch normalization steps are as follows:\n",
    "\n",
    "1. Compute the mini-batch mean:\n",
    "$$ \n",
    "\\mu_B = \\frac{1}{m} \\sum_{i=1}^m x_i \n",
    "$$\n",
    "\n",
    "2. Compute the mini-batch variance:\n",
    "$$ \n",
    "\\sigma_B^2 = \\frac{1}{m} \\sum_{i=1}^m (x_i - \\mu_B)^2\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "3. Normalize the input:\n",
    "$$\n",
    "\\hat{x}_i = \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "$$\n",
    "\n",
    "4. Scale and shift:\n",
    "$$\n",
    "y_i = \\gamma \\hat{x}_i + \\beta\n",
    "$$\n",
    "\n",
    "where $ \\gamma $ and $ \\beta $ are learnable parameters that allow the model to undo normalization if needed, and $ \\epsilon $ is a small constant for numerical stability.\n",
    "\n",
    "---\n",
    "\n",
    "### When input $ X \\in \\mathbb{R}^{B \\times C \\times H \\times W} $ is a batch of image features:\n",
    "\n",
    "BatchNorm is applied **per channel**, across batch and spatial dimensions:\n",
    "\n",
    "1. Compute mean:\n",
    "   $$\n",
    "   \\mu_c = \\frac{1}{BHW} \\sum_{b=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} X_{bchw}\n",
    "   $$\n",
    "\n",
    "2. Compute variance:\n",
    "   $$\n",
    "   \\sigma_c^2 = \\frac{1}{BHW} \\sum_{b=1}^{B} \\sum_{h=1}^{H} \\sum_{w=1}^{W} \\left(X_{bchw} - \\mu_c\\right)^2\n",
    "   $$\n",
    "\n",
    "3. Normalize:\n",
    "   $$\n",
    "   \\hat{X}_{bchw} = \\frac{X_{bchw} - \\mu_c}{\\sqrt{\\sigma_c^2 + \\epsilon}}\n",
    "   $$\n",
    "\n",
    "4. Scale and shift:\n",
    "   $$\n",
    "   Y_{bchw} = \\gamma_c \\hat{X}_{bchw} + \\beta_c\n",
    "   $$\n",
    "\n",
    "Where $ \\gamma_c $, $ \\beta_c $ are learnable (`affine`) parameters per channel.\n",
    "\n",
    "`momentum`: $\\hat{x}_{\\text{new}} = (1 - \\text{momentum}) \\cdot \\hat{x} + \\text{momentum} \\cdot x_t$, where $\\hat{x}$ is estimated statistic i.e. `running_mean` and $x_t$ is the new observed value i.e. `batch_mean`\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./assets/batch-norm.png\" alt=\"\" width=\"350\"/>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "Vairance computation:\n",
    "$$\n",
    "\\mathrm{Var}[x_c] = \\mathbb{E}[(x_c)^2] - \\left(\\mathbb{E}[x_c]\\right)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8fb0ed-ba7f-4d04-a79c-abd321b866f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_channels, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps # ϵ for numerical stability\n",
    "        self.momentum = momentum # for exponential moving average\n",
    "        self.affine = affine\n",
    "        self.track_running_stats = track_running_stats\n",
    "\n",
    "        # Learnable parameters for scale and shift\n",
    "        if self.affine:\n",
    "            self.scale = nn.Parameter(torch.ones(num_channels)) # γ\n",
    "            self.shift = nn.Parameter(torch.zeros(num_channels)) # β\n",
    "\n",
    "        # Buffers to store exponential moving averages of mean and variance\n",
    "        if self.track_running_stats:\n",
    "            # register tensor as a part of BatchNorm state w/o making it a learnable parameter\n",
    "            self.register_buffer(\"exp_mean\", torch.zeros(num_channels))\n",
    "            self.register_buffer(\"exp_var\", torch.ones(num_channels))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size = x.shape[0] # [B, C, H, W] or [B, C, ...]\n",
    "\n",
    "        # Reshape tensor to shape: [B, C, H * W]\n",
    "        reshaped_x = x.view(batch_size, self.num_channels, -1)\n",
    "\n",
    "        if self.training: # Defined in base class, tracks whether module is in training or evaluation mode\n",
    "\n",
    "            # Calculate batch mean and variance\n",
    "            mean = reshaped_x.mean(dim=[0, 2]) # o/p shape: [C]\n",
    "            \n",
    "            # Compute variance efficiently (can use: var = x.var(dim=[0, 2], unbiased=False))\n",
    "            x_squared_mean = (reshaped_x ** 2).mean(dim=[0, 2]) # o/p shape: [C]\n",
    "            mean_square = (mean ** 2)\n",
    "            var = x_squared_mean - mean_square # o/p shape: [C]\n",
    "\n",
    "            if self.track_running_stats:\n",
    "                self.exp_mean = (1 - self.momentum) * self.exp_mean + self.momentum * mean\n",
    "                self.exp_var = (1 - self.momentum) * self.exp_var + self.momentum * var\n",
    "        else:\n",
    "            # Evaluation mode: Use stored moving averages \n",
    "            mean = self.exp_mean\n",
    "            var = self.exp_var\n",
    "\n",
    "        # Normalize\n",
    "        # Add dimensions to [C] for broadcasting properly\n",
    "        x_hat = (x - mean[None, :, None, None]) / torch.sqrt(var[None, :, None, None] + self.eps)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        if self.affine:\n",
    "            # The learnable parameters γ and β are defined per channel so \n",
    "            # reshape gamma and beta to [1, C, 1, 1] for broadcasting.\n",
    "            scale = self.scale.view(1, -1, 1, 1)\n",
    "            shift = self.shift.view(1, -1, 1, 1)\n",
    "            x_hat = scale * x_hat + shift\n",
    "            \n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a815298c-38b7-4dec-be42-ee99c1a602ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape = torch.Size([4, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "bn = BatchNorm(3)\n",
    "x = torch.randn(4, 3, 8, 8)\n",
    "y = bn(x)\n",
    "print(f\"{y.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099c243-0663-4032-91b5-cda2e086ee6c",
   "metadata": {},
   "source": [
    "# [Layer Normalization](https://arxiv.org/pdf/1607.06450)\n",
    "\n",
    "Layer Normalization is a normalization technique used in neural networks to stabilize training, especially in recurrent networks (RNNs) and transformers.\n",
    "\n",
    "LayerNorm normalizes across the features of each individual example.\n",
    "\n",
    "It is generally used for NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "### When input $ X \\in \\mathbb{R}^{B \\times d} $, i.e A batch of feature vectors (e.g. embeddings), where:\n",
    "\n",
    "- $ B $ is the batch size\n",
    "- $ d $ is the feature dimension\n",
    "- $ \\gamma, \\beta \\in \\mathbb{R}^{d} $ are learnable parameters\n",
    "\n",
    "$$\n",
    "\\text{LN}(X) = \\gamma \\cdot \\frac{X - \\mathbb{E}_{d}[X]}{\\sqrt{\\mathrm{Var}_{d}[X] + \\epsilon}} + \\beta\n",
    "$$\n",
    "\n",
    "Where:\n",
    "$$\n",
    "\\mathbb{E}_{d}[X] = \\frac{1}{d} \\sum_{i=1}^{d} X_i \\quad \\text{(mean across features)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\mathrm{Var}_{d}[X] = \\frac{1}{d} \\sum_{i=1}^{d} (X_i - \\mathbb{E}_{d}[X])^2 \\quad \\text{(variance across features)}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### When input $ X \\in \\mathbb{R}^{L \\times B \\times d} $, i.e A sequence of feature vectors (e.g. transformer input), where:\n",
    "\n",
    "- $ L $ is the sequence length\n",
    "- $ B $ is the batch size\n",
    "- $ d $ is the feature dimension\n",
    "- $ \\gamma, \\beta \\in \\mathbb{R}^{d} $ are learnable parameters\n",
    "\n",
    "$$\n",
    "\\text{LN}(X) = \\gamma \\cdot \\frac{X - \\mathbb{E}_{d}[X]}{\\sqrt{\\mathrm{Var}_{d}[X] + \\epsilon}} + \\beta\n",
    "$$\n",
    "\n",
    "Normalize across the feature dimension $ d $ for each time step and each sample.\n",
    "\n",
    "---\n",
    "\n",
    "In Layer Normalization, two learnable parameters are introduced for each feature dimension:\n",
    "- $ \\textbf{Gain} $ (also called $ \\it{scale} $): $ \\gamma \\in \\mathbb{R}^{d} $\n",
    "- $ \\textbf{Bias} $ (also called $ \\it{shift} $): $ \\beta \\in \\mathbb{R}^{d} $\n",
    "\n",
    "These parameters are applied after normalizing the input, to allow the model to restore or adjust the representation scale if needed.\n",
    "\n",
    "After normalization, all inputs have:\n",
    "- Mean ≈ 0\n",
    "- Variance ≈ 1\n",
    "\n",
    "That might limit the model's expressiveness, so we give it the flexibility to learn:\n",
    "\n",
    "- A new scale (gain $ \\gamma $) e.g., “stretch” certain features\n",
    "- A new offset (bias $ \\beta $) e.g., “shift” feature means\n",
    "\n",
    "This allows the model to undo normalization if it wants, or apply custom transformations per feature.\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./assets/lyr-norm.png\" alt=\"\" width=\"350\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bd1ecdc-5446-40f5-95e1-7204223751f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-05, elementwise_affine=True):\n",
    "        super().__init__()\n",
    "        self.normalized_shape = (normalized_shape,) if isinstance(normalized_shape, int) else tuple(normalized_shape)\n",
    "        self.eps = eps\n",
    "        self.elementwise_affine = elementwise_affine\n",
    "\n",
    "        if self.elementwise_affine:\n",
    "            self.gain = nn.Parameter(torch.ones(normalized_shape))\n",
    "            self.bias = nn.Parameter(torch.zeros(normalized_shape))\n",
    "        else:\n",
    "            # Register tensors as learnable\n",
    "            self.register_parameter('gain', None)\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Compute mean and variance over the last normalized_shape dimensions\n",
    "        dims = tuple(range(-len(self.normalized_shape), 0)) # e.g. (-1,) for 1-D, (-2, -1) for 2-D\n",
    "        # Another way: dims = [-(i + 1) for i in range(len(self.normalized_shape))]\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        var = x.var(dim=dims, unbiased=False, keepdim=True)\n",
    "\n",
    "        # Normalize\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        # Apply elementwise affine transformation\n",
    "        if self.elementwise_affine:\n",
    "            x_hat = self.gain * x_hat + self.bias\n",
    "\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6182a7f1-c102-4414-a3e0-ba79e1e4d171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape = torch.Size([4, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = torch.randn(4, 3, 8, 8)\n",
    "normalized_shape = x.shape[2:] # H x W\n",
    "ln = LayerNorm(normalized_shape)\n",
    "y = ln(x)\n",
    "print(f\"{y.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2766f277-388f-43c2-8635-2147c89d238e",
   "metadata": {},
   "source": [
    "# [Instance Normalization](https://arxiv.org/pdf/1607.08022)\n",
    "\n",
    "Instance Normalization (**IN**) is a type of normalization commonly used in Computer Vision tasks, especially in Style Transfer and Image Generation\n",
    "\n",
    "\n",
    "Instance Normalization normalizes each sample and each channel independently, across spatial dimensions only.\n",
    "\n",
    "Let the input be a 4-D tensor: $X \\in \\mathbb{R}^{B \\times C \\times H \\times W}$ (e.g. batch of images)\n",
    "\n",
    "For each sample $ b \\in \\{1, \\dots, B\\} $ and each channel $ c \\in \\{1, \\dots, C\\} $, compute:\n",
    "\n",
    "$$\n",
    "\\mu_{bc} = \\frac{1}{HW} \\sum_{h=1}^{H} \\sum_{w=1}^{W} X_{bchw}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{bc}^2 = \\frac{1}{HW} \\sum_{h=1}^{H} \\sum_{w=1}^{W} (X_{bchw} - \\mu_{bc})^2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{IN}(X_{bchw}) = \\gamma_c \\cdot \\frac{X_{bchw} - \\mu_{bc}}{\\sqrt{\\sigma_{bc}^2 + \\epsilon}} + \\beta_c\n",
    "$$\n",
    "\n",
    "where:\n",
    "- $ \\gamma_c, \\beta_c \\in \\mathbb{R} $ are learnable scale and shift parameters for each channel $ c $\n",
    "- $ \\epsilon $ is a small constant for numerical stability\n",
    "\n",
    "<center>\n",
    "<img src=\"./assets/inst-norm.png\" alt=\"\" width=\"350\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc35f4c0-0dff-479e-ab7f-88d448262879",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    def __init__(self, num_channels, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        self.num_channels = num_channels\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        # Learnable parameters for scale and shift\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(num_channels))  # scale (γ)\n",
    "            self.beta = nn.Parameter(torch.zeros(num_channels))  # shift (β)\n",
    "        else:\n",
    "            # Register tensors as learnable\n",
    "            self.register_parameter('gamma', None)\n",
    "            self.register_parameter('beta', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Reshape x to [B * C, H * W]\n",
    "        x_reshaped = x.view(B * C, -1)\n",
    "\n",
    "        # Compute mean and variance per (B, C)\n",
    "        mean = x_reshaped.mean(dim=1, keepdim=True) # o/p shape: [B * C, 1]\n",
    "        var = x_reshaped.var(dim=1, unbiased=False, keepdim=True) # o/p shape: [B * C, 1]\n",
    "\n",
    "        # Normalize\n",
    "        x_norm = (x_reshaped - mean) / torch.sqrt(var + self.eps) # o/p shape: [B * C, H * W]\n",
    "\n",
    "        # Reshape back to [B, C, H, W]\n",
    "        x_norm = x_norm.view(B, C, H, W)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        if self.affine:\n",
    "            # The learnable parameters γ and β are defined per channel so \n",
    "            # reshape gamma and beta to [1, C, 1, 1] for broadcasting.\n",
    "            gamma = self.gamma.view(1, C, 1, 1)\n",
    "            beta = self.beta.view(1, C, 1, 1)\n",
    "            x_norm = gamma * x_norm + beta\n",
    "\n",
    "        return x_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26c3b0a-1b83-421d-8124-58f409434402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape = torch.Size([4, 3, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = torch.randn(4, 3, 8, 8)\n",
    "i_norm = InstanceNorm(3)\n",
    "y = i_norm(x)\n",
    "print(f\"{y.shape = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1da21b-25f6-4d0f-a3c9-abd2db29939b",
   "metadata": {},
   "source": [
    "# [Group Normalization](https://arxiv.org/pdf/1803.08494)\n",
    "\n",
    "Group Normalization (**GN**) is a normalization technique introduced as a more stable alternative to Batch Normalization, especially when batch sizes are small.\n",
    "\n",
    "Group Normalization splits the channels of the input tensor into groups, then normalizes each group independently over the spatial dimensions and the group's channels. This provides the benefits of normalization like BatchNorm but does not depend on batch size.\n",
    "\n",
    "Let the input be a 4-D tensor: $X \\in \\mathbb{R}^{B \\times C \\times H \\times W}$ (e.g. batch of images)\n",
    "\n",
    "where:\n",
    "- $ B $ is the batch size\n",
    "- $ C $ is the number of channels\n",
    "- $ H $, $ W $ are the spatial dimensions\n",
    "\n",
    "Group Normalization divides the $ C $ channels into $ G $ groups, each containing $ C/G $ channels. For each sample $ b \\in \\{1, \\dots, B\\} $ and each group $ g \\in \\{1, \\dots, G\\} $, it computes the mean and variance over all values in that group (across the group’s channels and spatial dimensions):\n",
    "\n",
    "$$\n",
    "\\mu_{bg} = \\frac{1}{m} \\sum_{i=1}^{m} X_{bg,i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma_{bg}^2 = \\frac{1}{m} \\sum_{i=1}^{m} \\left(X_{bg,i} - \\mu_{bg}\\right)^2\n",
    "$$\n",
    "\n",
    "where:\n",
    "$$\n",
    "m = \\frac{C}{G} \\times H \\times W\n",
    "$$\n",
    "\n",
    "\n",
    "Then, each element $ X_{bg,i} $ is normalized and transformed using learnable parameters $ \\gamma \\in \\mathbb{R}^{C} $, $ \\beta \\in \\mathbb{R}^{C} $:\n",
    "\n",
    "$$\n",
    "\\text{GN}(X_{bg,i}) = \\gamma_{c(i)} \\cdot \\frac{X_{bg,i} - \\mu_{bg}}{\\sqrt{\\sigma_{bg}^2 + \\epsilon}} + \\beta_{c(i)}\n",
    "$$\n",
    "\n",
    "where $ c(i) $ maps element $ i $ back to its original channel index within the input.\n",
    "\n",
    "\n",
    "\n",
    "<center>\n",
    "<img src=\"./assets/grp-norm.png\" alt=\"\" width=\"350\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7a07386-a67e-4a39-8f21-dba5d102eb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GroupNorm(nn.Module):\n",
    "    def __init__(self, num_channels, num_groups, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        assert num_channels % num_groups == 0, \"num_channels must be divisible by num_groups\"\n",
    "        self.num_channels = num_channels\n",
    "        self.num_groups = num_groups\n",
    "        self.eps = eps\n",
    "        self.affine = affine\n",
    "\n",
    "        # Learnable parameters for scale and shift\n",
    "        if self.affine:\n",
    "            self.gamma = nn.Parameter(torch.ones(num_channels))  # scale (γ)\n",
    "            self.beta = nn.Parameter(torch.zeros(num_channels))  # shift (β)\n",
    "        else:\n",
    "            # Register tensors as learnable\n",
    "            self.register_parameter('gamma', None)\n",
    "            self.register_parameter('beta', None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        G = self.num_groups\n",
    "\n",
    "        # Reshape x to [B, G, C/G, H, W]\n",
    "        x = x.view(B, G, C // G, H, W)\n",
    "\n",
    "        # Compute mean and variance over (C/G, H, W), i.e. indices [2, 3, 4]\n",
    "        mean = x.mean(dim=(2, 3, 4), keepdim=True)\n",
    "        var = x.var(dim=(2, 3, 4), keepdim=True, unbiased=False)\n",
    "\n",
    "        # Normalize\n",
    "        x = (x - mean) / torch.sqrt(var + self.eps)\n",
    "\n",
    "        # Reshape x back to [B, C, H, W] to restore original x structure\n",
    "        x = x.view(B, C, H, W)\n",
    "\n",
    "        # Apply affine transformation\n",
    "        if self.affine:\n",
    "            # The learnable parameters γ and β are defined per channel so \n",
    "            # reshape gamma and beta to [1, C, 1, 1] for broadcasting.\n",
    "            gamma = self.gamma.view(1, C, 1, 1)\n",
    "            beta = self.beta.view(1, C, 1, 1)\n",
    "            x = gamma * x + beta\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4f4cd3-b1ee-43d7-a966-be47bfc27255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y.shape = torch.Size([4, 32, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "x = torch.randn(4, 32, 64, 64)\n",
    "num_channels = 32\n",
    "num_groups = 8\n",
    "gn = GroupNorm(num_channels, num_groups)\n",
    "y = gn(x)\n",
    "print(f\"{y.shape = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e7a59e-9dd7-4e02-b83d-b600fb9bd744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
